{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from ex5.util import parse_dataset\n",
    "from ex5.conformal import ConformalBoostedSeqTree\n",
    "from ex5.conformal import custom_train_test_split\n",
    "\n",
    "\n",
    "#DATASET_PATH = \"../datasets/pioneer.txt\"  ## 160 lines\n",
    "#DATASET_PATH = \"../datasets/auslan2.txt\"  ## 200 lines\n",
    "DATASET_PATH = \"../datasets/context.txt\"  ## 240 lines\n",
    "#DATASET_PATH = \"../datasets/aslbu.txt\"  #### 424 lines\n",
    "#DATASET_PATH = \"../datasets/skating.txt\"  ## 530 lines\n",
    "# DATASET_PATH = \"../datasets/reuters.txt\"  # 1010 lines\n",
    "#DATASET_PATH = \"../datasets/webkb.txt\"  ### 3667 lines\n",
    "#DATASET_PATH = \"../datasets/news.txt\"  #### 4976 lines\n",
    "#DATASET_PATH = \"../datasets/unix.txt\"  #### 5472 lines\n",
    "\n",
    "# other datasets with 2 classes\n",
    "#DATASET_PATH = \"../datasets/activity.txt\"  # 35 lines\n",
    "#DATASET_PATH = \"../datasets/question.txt\"  # 1730 lines\n",
    "#DATASET_PATH = \"../datasets/epitope.txt\"  # 2392 lines\n",
    "#DATASET_PATH = \"../datasets/gene.txt\"  # 2942 lines\n",
    "#DATASET_PATH = \"../datasets/robot.txt\"  # 4302 lines\n",
    "\n",
    "ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset with ratio 0.8\n",
      "Dataset size: 240\n",
      "Class 1\n",
      "data size: 44\n",
      "Class 1: 35 train, 9 test\n",
      "Class 2\n",
      "data size: 48\n",
      "Class 2: 38 train, 10 test\n",
      "Class 3\n",
      "data size: 48\n",
      "Class 3: 38 train, 10 test\n",
      "Class 4\n",
      "data size: 50\n",
      "Class 4: 40 train, 10 test\n",
      "Class 5\n",
      "data size: 50\n",
      "Class 5: 40 train, 10 test\n"
     ]
    }
   ],
   "source": [
    "df = parse_dataset(DATASET_PATH, add_padding=True)\n",
    "\n",
    "# divide training and test sets\n",
    "X, X_test, Y, Y_test = custom_train_test_split(df[\"s\"].to_numpy(), df[\"y\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 1\n",
      "Training model for class 1\n",
      "Fitting Classifier\n",
      "Calibrating model for class 1\n",
      "class: 2\n",
      "Training model for class 2\n",
      "Fitting Classifier\n",
      "Calibrating model for class 2\n",
      "class: 3\n",
      "Training model for class 3\n",
      "Fitting Classifier\n",
      "Calibrating model for class 3\n",
      "class: 4\n",
      "Training model for class 4\n",
      "Fitting Classifier\n",
      "Calibrating model for class 4\n",
      "class: 5\n",
      "Training model for class 5\n",
      "Fitting Classifier\n",
      "Calibrating model for class 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ex5.conformal.ConformalBoostedSeqTree at 0x770adff6d7c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConformalBoostedSeqTree()\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\n",
    "    f\"models/{DATASET_PATH.split('/')[-1].split('.')[0]}_itrs_{ITERATIONS}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"models_activity_itrs_20_2024-06-07_14-54-24.pkl\"\n",
    "# model.load(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNIFICANCE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['2', '3', '4', '5']\n",
      "Real: 1 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 2 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4']\n",
      "Real: 3 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '4', '5']\n",
      "Real: 3 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 4 - Predicted: ['1', '2', '3', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4']\n",
      "Real: 5 - Predicted: ['1', '2', '3', '4', '5']\n",
      "Accuracy: 0.5714285714285714\n",
      "Accuracy strong: 0.061224489795918366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_test, SIGNIFICANCE)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Real: {Y_test[i]} - Predicted: {predictions[i]}\")\n",
    "\n",
    "# compute accuracy\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if str(Y_test[i]) in predictions[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy: {correct/len(predictions)}\")\n",
    "\n",
    "# compute accuracy strong\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if str(Y_test[i]) == predictions[i][0]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy strong: {correct/len(predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['4']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 1 - Predicted: ['1']\n",
      "Real: 2 - Predicted: []\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: []\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 2 - Predicted: ['1', '4']\n",
      "Real: 2 - Predicted: ['1']\n",
      "Real: 3 - Predicted: ['3', '5']\n",
      "Real: 3 - Predicted: ['3']\n",
      "Real: 3 - Predicted: ['3', '5']\n",
      "Real: 3 - Predicted: ['3']\n",
      "Real: 3 - Predicted: ['3', '4']\n",
      "Real: 3 - Predicted: ['3', '5']\n",
      "Real: 3 - Predicted: ['4']\n",
      "Real: 3 - Predicted: ['3', '5']\n",
      "Real: 3 - Predicted: ['3']\n",
      "Real: 3 - Predicted: ['3', '5']\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: []\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: []\n",
      "Real: 4 - Predicted: []\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 4 - Predicted: ['4']\n",
      "Real: 5 - Predicted: ['4', '5']\n",
      "Real: 5 - Predicted: ['3', '5']\n",
      "Real: 5 - Predicted: ['5']\n",
      "Real: 5 - Predicted: []\n",
      "Real: 5 - Predicted: ['3', '4']\n",
      "Real: 5 - Predicted: ['5']\n",
      "Real: 5 - Predicted: ['4', '5']\n",
      "Real: 5 - Predicted: ['3', '5']\n",
      "Real: 5 - Predicted: ['5']\n",
      "Real: 5 - Predicted: []\n",
      "Accuracy: 0.6326530612244898\n",
      "Accuracy strong: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# redict using the BoostedSeqTree model\n",
    "predictions = model.predict_alternative(X_test)\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Real: {Y_test[i]} - Predicted: {predictions[i]}\")\n",
    "\n",
    "# accuracy\n",
    "# count as correct if the real class is in the prediction set\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if Y_test[i] in predictions[i]:\n",
    "        correct += 1\n",
    "print(f\"Accuracy: {correct/len(predictions)}\")\n",
    "\n",
    "# accuracy\n",
    "# count as correct if the real class is the only one in the prediction set\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if len(predictions[i]) == 1 and Y_test[i] in predictions[i]:\n",
    "        correct += 1\n",
    "print(f\"Accuracy strong: {correct/len(predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : [(0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False]))]\n",
      "Error rate for class 1: 0.8775510204081632\n",
      "Error : []\n",
      "Error rate for class 2: 1.0\n",
      "Error : [(0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (1, array([False, False]))]\n",
      "Error rate for class 3: 0.8571428571428571\n",
      "Error : [(0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (1, array([False, False]))]\n",
      "Error rate for class 4: 0.8775510204081632\n",
      "Error : [(1, array([False, False])), (1, array([ True, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False])), (0, array([False, False]))]\n",
      "Error rate for class 5: 0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([np.array(i) for i in X_test])\n",
    "\n",
    "classes = np.unique(Y).tolist()\n",
    "\n",
    "\n",
    "def class_to_pos(current_class, real_class):\n",
    "    if current_class == real_class:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "for c, phi in model.PHI.items():\n",
    "    regions = phi.predict(X_test, significance=SIGNIFICANCE)\n",
    "    error = list(\n",
    "        filter(\n",
    "            lambda x: not x[1][x[0]],\n",
    "            [(class_to_pos(Y_test[i], c), r) for i, r in enumerate(regions)],\n",
    "        )\n",
    "    )\n",
    "    print(f\"Error : {error}\")\n",
    "\n",
    "    error_p = np.array(\n",
    "        [r[class_to_pos(Y_test[i], c)] for i, r in enumerate(regions)]\n",
    "    ).mean()\n",
    "    print(f\"Error rate for class {c}: {error_p}\")\n",
    "\n",
    "    error_rate = len(error) / len(regions)\n",
    "    res = np.array([r.sum() for r in regions]).mean()\n",
    "    # print(f\"results for class {c}: {res}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
